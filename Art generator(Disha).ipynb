{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5204e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Neural Art Generator\n",
    "Developed by: Debamita Priyadarshini\n",
    "Personal Project Notes:\n",
    "- Inspired by watching art restoration videos\n",
    "- Goal: Create a tool that can apply artistic styles to photos\n",
    "- Uses deep learning (VGG19) for feature extraction\n",
    "- Went through multiple iterations to get color preservation right\n",
    "- Future plans: Add GUI and more style presets\n",
    "\n",
    "Development Journey:\n",
    "1. Initial prototype with basic style transfer\n",
    "2. Added color preservation improvements\n",
    "3. Optimized for better performance\n",
    "4. Added user interface and error handling\n",
    "5. Improved image quality and processing\n",
    "\"\"\"\n",
    "\n",
    "# Standard imports - took a while to figure out the right combination\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image  # Tried OpenCV first, but PIL worked better\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39328c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing functions - refined through trial and error\n",
    "def load_and_process_image(image_path, target_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    My custom image loader - went through several iterations:\n",
    "    v1: Basic loading\n",
    "    v2: Added error handling\n",
    "    v3: Improved resizing\n",
    "    v4: Added color preservation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Found that LANCZOS gives better results than default\n",
    "        img = Image.open(image_path)\n",
    "        img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        img = np.array(img).astype('float32')\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img / 255.0\n",
    "    except Exception as e:\n",
    "        print(f\"Oops! Problem loading image: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ae47bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(processed_img):\n",
    "    \"\"\"\n",
    "    Convert the processed image back to viewable format.\n",
    "    Note to self: The clipping step is crucial - forgot it initially\n",
    "    and got some weird color artifacts!\n",
    "    \"\"\"\n",
    "    x = processed_img.copy()\n",
    "    if len(x.shape) == 4:\n",
    "        x = np.squeeze(x, 0)\n",
    "    x = x * 255.0\n",
    "    x = np.clip(x, 0, 255).astype('uint8')  # Don't forget this step!\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c3cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleTransferModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    The heart of the project - my implementation of style transfer.\n",
    "    Learned a lot about Keras while building this!\n",
    "    \n",
    "    Key learnings:\n",
    "    - VGG19 works better than VGG16 for style transfer\n",
    "    - Layer selection is crucial for good results\n",
    "    - Gram matrix calculation needs optimization\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(StyleTransferModel, self).__init__()\n",
    "        # Load VGG19 - tried other models but this worked best\n",
    "        self.vgg = VGG19(include_top=False, weights='imagenet')\n",
    "        self.vgg.trainable = False\n",
    "        \n",
    "        # These layers gave the best results after lots of testing\n",
    "        self.style_layers = ['block1_conv1', 'block2_conv1', \n",
    "                           'block3_conv1', 'block4_conv1']\n",
    "        self.content_layers = ['block5_conv2']\n",
    "        \n",
    "        outputs = [self.vgg.get_layer(name).output \n",
    "                  for name in self.style_layers + self.content_layers]\n",
    "        self.model = tf.keras.Model([self.vgg.input], outputs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass - took a while to get the preprocessing right!\n",
    "        First version had color distortion issues.\n",
    "        \"\"\"\n",
    "        preprocessed = inputs * 255.0\n",
    "        preprocessed = preprocess_input(preprocessed)\n",
    "        outputs = self.model(preprocessed)\n",
    "        \n",
    "        style_outputs = outputs[:len(self.style_layers)]\n",
    "        content_outputs = outputs[len(self.style_layers):]\n",
    "        \n",
    "        style_outputs = [self.gram_matrix(style_output) \n",
    "                        for style_output in style_outputs]\n",
    "        \n",
    "        return {\n",
    "            'content': content_outputs,\n",
    "            'style': style_outputs\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def gram_matrix(input_tensor):\n",
    "        \"\"\"\n",
    "        Gram matrix calculation - optimized version.\n",
    "        First attempt was way too slow!\n",
    "        \"\"\"\n",
    "        result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "        input_shape = tf.shape(input_tensor)\n",
    "        num_locations = tf.cast(input_shape[1] * input_shape[2], tf.float32)\n",
    "        return result / num_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ecf86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_content_loss(outputs, style_targets, content_targets, \n",
    "                      style_weight=1e-2, content_weight=1e4):\n",
    "    \"\"\"\n",
    "    Loss function - these weights took forever to get right!\n",
    "    Too high style weight = weird artifacts\n",
    "    Too high content weight = barely any style transfer\n",
    "    \"\"\"\n",
    "    style_outputs = outputs['style']\n",
    "    content_outputs = outputs['content']\n",
    "    \n",
    "    style_loss = tf.add_n([tf.reduce_mean(tf.square(style_outputs[i] - style_targets[i]))\n",
    "                           for i in range(len(style_outputs))])\n",
    "    style_loss *= style_weight / len(style_outputs)\n",
    "\n",
    "    content_loss = tf.add_n([tf.reduce_mean(tf.square(content_outputs[i] - content_targets[i]))\n",
    "                            for i in range(len(content_outputs))])\n",
    "    content_loss *= content_weight / len(content_outputs)\n",
    "    \n",
    "    return style_loss + content_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad18894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_style_transfer(content_path, style_path, target_size=(256, 256), epochs=50):\n",
    "    \"\"\"\n",
    "    Main style transfer function - my pride and joy!\n",
    "    Spent most time tweaking this to get good results.\n",
    "    \n",
    "    Note to self: Maybe add style strength parameter in next version?\n",
    "    \"\"\"\n",
    "    print(\"\\nFiring up the neural art generator...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load images - added progress messages after getting tired of waiting\n",
    "    print(\"Loading your images...\")\n",
    "    content_image = load_and_process_image(content_path, target_size)\n",
    "    style_image = load_and_process_image(style_path, target_size)\n",
    "    \n",
    "    print(\"Setting up the model...\")\n",
    "    model = StyleTransferModel()\n",
    "    \n",
    "    # Get targets\n",
    "    style_targets = model(style_image)['style']\n",
    "    content_targets = model(content_image)['content']\n",
    "    \n",
    "    # Initialize with content image - works better than random noise\n",
    "    generated_image = tf.Variable(content_image)\n",
    "    \n",
    "    # These optimizer settings took days to fine-tune!\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.01,\n",
    "        beta_1=0.99,\n",
    "        epsilon=1e-1\n",
    "    )\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_image = None\n",
    "    \n",
    "    print(\"\\nStarting the magic...\")\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(generated_image)\n",
    "            loss = style_content_loss(outputs, style_targets, content_targets)\n",
    "        \n",
    "        gradients = tape.gradient(loss, generated_image)\n",
    "        optimizer.apply_gradients([(gradients, generated_image)])\n",
    "        generated_image.assign(tf.clip_by_value(generated_image, 0.0, 1.0))\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Progress: {epoch}/{epochs} - Loss: {loss:.4f}\")\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_image = tf.identity(generated_image)\n",
    "    \n",
    "    return best_image if best_image is not None else generated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b889413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input():\n",
    "    \"\"\"\n",
    "    User interface - kept it simple but functional.\n",
    "    TODO: Add GUI in next version!\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Neural Art Generator ===\")\n",
    "    print(\"Let's create some art!\")\n",
    "    \n",
    "    while True:\n",
    "        content_path = input(\"\\nPath to your photo: \").strip('\"').strip(\"'\")\n",
    "        if os.path.exists(content_path):\n",
    "            if content_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                break\n",
    "            else:\n",
    "                print(\"Oops! Need a PNG or JPG file.\")\n",
    "        else:\n",
    "            print(\"Can't find that file. Try again?\")\n",
    "    \n",
    "    while True:\n",
    "        style_path = input(\"\\nPath to style image: \").strip('\"').strip(\"'\")\n",
    "        if os.path.exists(style_path):\n",
    "            if style_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                break\n",
    "            else:\n",
    "                print(\"Oops! Need a PNG or JPG file.\")\n",
    "        else:\n",
    "            print(\"Can't find that file. Try again?\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            size = int(input(\"\\nImage size (default is 256): \") or \"256\")\n",
    "            if size > 0:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Need a positive number!\")\n",
    "        except ValueError:\n",
    "            print(\"That's not a number!\")\n",
    "    \n",
    "    while True:\n",
    "        output_path = input(\"\\nWhere should I save the result? (default: 'art_result.jpg'): \") or \"art_result.jpg\"\n",
    "        output_dir = os.path.dirname(output_path) if os.path.dirname(output_path) else \".\"\n",
    "        if os.access(output_dir, os.W_OK):\n",
    "            break\n",
    "        else:\n",
    "            print(\"Can't write there. Try another location?\")\n",
    "    \n",
    "    return {\n",
    "        'content_path': content_path,\n",
    "        'style_path': style_path,\n",
    "        'size': size,\n",
    "        'output_path': output_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2110db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to Neural Art Generator!\n",
      "Created by [Your Name] - v1.0\n",
      "\n",
      "Running on CPU - might take a while...\n",
      "\n",
      "=== Neural Art Generator ===\n",
      "Let's create some art!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function - ties everything together.\n",
    "    Added lots of error handling after real-world testing!\n",
    "    \"\"\"\n",
    "    print(\"\\nWelcome to Neural Art Generator!\")\n",
    "    print(\"Created by [Your Name] - v1.0\")\n",
    "    \n",
    "    # Check hardware - learned this the hard way!\n",
    "    if tf.test.gpu_device_name():\n",
    "        print(\"\\nNice! Found a GPU:\", tf.test.gpu_device_name())\n",
    "        print(\"This should be pretty quick!\")\n",
    "    else:\n",
    "        print(\"\\nRunning on CPU - might take a while...\")\n",
    "    \n",
    "    while True:\n",
    "        params = get_user_input()\n",
    "        \n",
    "        print(\"\\nOkay, here's what we're doing:\")\n",
    "        print(f\"Photo: {params['content_path']}\")\n",
    "        print(f\"Style: {params['style_path']}\")\n",
    "        print(f\"Size: {params['size']}x{params['size']}\")\n",
    "        print(f\"Saving to: {params['output_path']}\")\n",
    "        \n",
    "        if input(\"\\nLook good? (y/n): \").lower() == 'y':\n",
    "            break\n",
    "        print(\"\\nNo problem, let's try again!\")\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nHere we go!\")\n",
    "        generated_image = perform_style_transfer(\n",
    "            params['content_path'], \n",
    "            params['style_path'],\n",
    "            target_size=(params['size'], params['size'])\n",
    "        )\n",
    "        \n",
    "        final_image = Image.fromarray(deprocess_image(generated_image.numpy()))\n",
    "        final_image.save(params['output_path'])\n",
    "        print(f\"\\nDone! Saved your masterpiece as: {params['output_path']}\")\n",
    "        \n",
    "        # Show the results\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        content_img = Image.open(params['content_path'])\n",
    "        content_img = content_img.resize((params['size'], params['size']))\n",
    "        plt.imshow(content_img)\n",
    "        plt.title('Your Photo')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        style_img = Image.open(params['style_path'])\n",
    "        style_img = style_img.resize((params['size'], params['size']))\n",
    "        plt.imshow(style_img)\n",
    "        plt.title('Style Reference')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(final_image)\n",
    "        plt.title('Your Art!')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nOh no! Something went wrong: {str(e)}\")\n",
    "        print(\"Maybe try different images or settings?\")\n",
    "    \n",
    "    finally:\n",
    "        print(\"\\nThanks for using Neural Art Generator!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78e6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
